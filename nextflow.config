plugins {
  id 'nf-schema@2.0.0'
}

manifest {
  name = 'nf-reads-profiler'
  author = 'Sunit Jain'
  homePage = 'https://github.com/fischbachlab/nf-profile-reads'
  description = 'Metaphlan and HUMANn'
  mainScript = 'main.nf'
  defaultBranch = 'main'
  version = '0.0.2'
}

// includeConfig "$projectDir/conf/aws_batch.config"
// includeConfig "$projectDir/conf/azurebatch.config"

params {

    /* 	Containers
     --------------------------------*/
    docker_container_humann4 = 'lightweightlabware/humann:4.0.0a1-1'
    docker_container_humann3 = "biobakery/humann:3.9"
    docker_container_metaphlan = "quay.io/biocontainers/metaphlan:4.2.2--pyhdfd78af_0"
    docker_container_multiqc = "quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0"
    docker_container_fastp = "quay.io/biocontainers/fastp:0.23.4--hadf994f_1"
    docker_container_aws = 'lightweightlabware/aws-cli-bash:ubuntu'
    docker_container_sra = 'lightweightlabware/sra-tools-bash'
    docker_container_medi = "lightweightlabware/medi:latest"

    // AWS config
    aws_region = 'us-east-1'

    /* 	Execution flow parameters
     --------------------------------*/

    config_profile_name        = 'Default profile'
    config_profile_description = 'nf-profile-reads default workflow'

    /* 	Execution flow parameters
     --------------------------------*/

    singleEnd = false  //Whether we the input reads are single or paired-end
    mergeReads = false
    annotation = true
    rna = false
    cache = true
    project= "none"
    prefix="output"
    input="az://nextflow-data/fetchngs/samplesheet/samplesheet.csv"
	  outdir="az://nextflow-analysis/workflows"
    rna = false       // Is the input data RNA? Requires "taxonomic_profile" to be set as well.
    taxonomic_profile = null    // <S3Path> Use in case metaphlan results are already available.
    annotation  = true  // whether annotation is enabled  or not
    skipHumann  = false // whether humann2 is executed or not

    /* 	Processing parameters
     --------------------------------*/

    //BowTie2 databases for MetaPhlAn
    metaphlan_index="mpa_vJan25_CHOCOPhlAnSGB_202503"
    metaphlan_db="/dbs/omicsdata/metagenome-dbs/metaphlan/metaphlan4/vJan25"
    // Separate MetaPhlAn database for HUMAnN 4 (should be compatible with HUMAnN 4 vOct22)
    humann_metaphlan_index="mpa_vOct22_CHOCOPhlAnSGB_202403"
    humann_metaphlan_db="/dbs/omicsdata/metagenome-dbs/metaphlan/metaphlan4/vOct22_202403"
    bt2options="very-sensitive" //presets options for BowTie2

    // ChocoPhlAn and UniRef databases for HUMANn analysis
    chocophlan="/dbs/omicsdata/metagenome-dbs/humann/4.0/chocophlan"
    uniref="/dbs/omicsdata/metagenome-dbs/humann/4.0/uniref/uniref"
    utility_mapping="/dbs/omicsdata/metagenome-dbs/humann/4.0/utility_mapping/utility_mapping"

    // Additional command line parameters
    humann_params=""
    
    // HUMAnN table processing parameters
    process_humann_tables = false  // Enable HUMAnN table regrouping
    humann_regroups = "uniref90_ko,uniref90_rxn"  // Comma-separated list of regroup types
    split_size = 100  // Maximum samples per split for memory management

    // SRA download settings
    max_retry_count = 3
    max_parallel_downloads = 3

    // Limit size
    nreads = 33333333
    minreads = 100000
    
    // MEDI quantification parameters
    enable_medi = false  // Enable MEDI quantification workflow
    medi_db_path = '/dbs/omicsdata/metagenome-dbs/MEDI/medi_db'  // Path to MEDI database
    medi_foods_file = '/dbs/omicsdata/metagenome-dbs/MEDI/medi_db/food_matches.csv'  // Path to foods file
    medi_food_contents_file = '/dbs/omicsdata/metagenome-dbs/MEDI/medi_db/food_contents.csv.gz'  // Path to food contents file
    confidence = 0.3  // Kraken2 confidence threshold
    consistency = 0.95  // Architeuthis filter consistency threshold
    entropy = 0.1  // Architeuthis filter entropy threshold
    multiplicity = 4  // Architeuthis filter multiplicity threshold
    mapping = false  // Enable mapping summary
    read_length = 150  // Read length for Bracken
    threshold = 10  // Bracken threshold
    batchsize = 400  // Batch size for Kraken2
    
    // MEDI fastp preprocessing parameters
    trim_front = 5  // Number of bases to trim from 5' end
    min_length = 50  // Minimum read length to keep
    quality_threshold = 20  // Minimum quality score to keep a base
    
    /* 	Initialisation
     --------------------------------*/


    //These are used to print version and help
    help = null
    version = null

    multiqc_config="$projectDir/conf/multiqc_config.yaml"
}


timeline {
  enabled = true
  overwrite = true
  file = "$params.outdir/$params.project/execution_reports/timeline.html"
}

report {
  enabled = true
  overwrite = true
  file = "$params.outdir/$params.project/execution_reports/report.html"
}

dag {
    enabled = true
    overwrite = true
    file = "$params.outdir/$params.project/execution_reports/pipeline_dag.html"
}

profiles {
    test {
        includeConfig 'conf/test.config'
    }
    azure {
        includeConfig 'conf/azurebatch.config'
    }
}

